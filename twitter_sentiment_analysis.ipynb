{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymSgi7MJcDlk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PkzlSNuocDln"
      },
      "outputs": [],
      "source": [
        "#Supress warnings\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "pd.set_option('display.max_columns',None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZdrkfC4cDlo"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Pip install Tweepy if you don't already have the package\n",
        "# !pip install tweepy\n",
        "\n",
        "# Imports\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import time\n",
        "import re \n",
        "from tweepy import OAuthHandler \n",
        "from textblob import TextBlob "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bkmp8YmQcDlp"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "Y539d0SBcDlp",
        "outputId": "96b6e5e2-3d9f-45d9-ce9f-f5f13f60ceeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to C:\\Users\\Devdatta\n",
            "[nltk_data]     Supnekar\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# nltk.download(\"vader_lexicon\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3H_GuW-cDlq"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jO7IhIHpcDlq"
      },
      "outputs": [],
      "source": [
        "sid = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxEYei1UcDlr"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvqg7Vk-cDls"
      },
      "outputs": [],
      "source": [
        "\n",
        "# keys and tokens from the Twitter Dev Console \n",
        "consumer_key = \"xxxxxx\"\n",
        "consumer_secret = \"xxxxx\"\n",
        "access_token = \"xxxxxx\"\n",
        "access_token_secret = \"0xxxxx\"\n",
        "\n",
        "# attempt authentication \n",
        "try: \n",
        "    # create OAuthHandler object \n",
        "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "    # set access token and secret \n",
        "    auth.set_access_token(access_token, access_token_secret)\n",
        "    # create tweepy API object to fetch tweets \n",
        "    api = tweepy.API(auth,wait_on_rate_limit=True)\n",
        "except: \n",
        "    print(\"Error: Authentication Failed\") "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWEBkL_0cDls"
      },
      "outputs": [],
      "source": [
        "def clean_tweet(tweet): \n",
        "    ''' \n",
        "    Utility function to clean tweet text by removing links, special characters \n",
        "    using simple regex statements. \n",
        "    '''\n",
        "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wLm7VUmcDlt"
      },
      "outputs": [],
      "source": [
        "def get_tweet_sentiment(score): \n",
        "    ''' \n",
        "    Utility function to classify sentiment of passed tweet \n",
        "    using textblob's sentiment method \n",
        "    '''\n",
        "    \n",
        "    if score > 0: \n",
        "        return 'positive'\n",
        "    elif score == 0: \n",
        "        return 'neutral'\n",
        "    else: \n",
        "        return 'negative'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hCpsjH4cDlu"
      },
      "source": [
        "Query by Text Search\n",
        "Function is focused on completing the query then providing a CSV file of that query using pandas`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0_qXJcPcDlv"
      },
      "outputs": [],
      "source": [
        "query = \"deep learning\" + \" \" + \"-filter:retweets\"\n",
        "count = 150\n",
        "# # Creation of query method using parameters\n",
        "# tweets = tweepy.Cursor(api.search,q=query).items(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEeV4sQqcDlw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PX7QPXnXcDlw"
      },
      "outputs": [],
      "source": [
        "tweets = api.search_tweets(q=query, lang=\"en\", count=count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gYh-QXGqcDlw",
        "outputId": "d73dc199-073f-4108-8a2f-63aa8f526917"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_api',\n",
              " '_json',\n",
              " 'author',\n",
              " 'contributors',\n",
              " 'coordinates',\n",
              " 'created_at',\n",
              " 'destroy',\n",
              " 'entities',\n",
              " 'favorite',\n",
              " 'favorite_count',\n",
              " 'favorited',\n",
              " 'geo',\n",
              " 'id',\n",
              " 'id_str',\n",
              " 'in_reply_to_screen_name',\n",
              " 'in_reply_to_status_id',\n",
              " 'in_reply_to_status_id_str',\n",
              " 'in_reply_to_user_id',\n",
              " 'in_reply_to_user_id_str',\n",
              " 'is_quote_status',\n",
              " 'lang',\n",
              " 'metadata',\n",
              " 'parse',\n",
              " 'parse_list',\n",
              " 'place',\n",
              " 'possibly_sensitive',\n",
              " 'retweet',\n",
              " 'retweet_count',\n",
              " 'retweeted',\n",
              " 'retweets',\n",
              " 'source',\n",
              " 'source_url',\n",
              " 'text',\n",
              " 'truncated',\n",
              " 'user']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(tweets[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CDvnD_UacDlx",
        "outputId": "b5aef635-a9a7-4e45-ea0f-13d491910ac0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "datetime.datetime(2022, 4, 17, 13, 29, 1, tzinfo=datetime.timezone.utc)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets[3].created_at"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "322jqmwKcDlx"
      },
      "outputs": [],
      "source": [
        "# Pulling information from tweets iterable object\n",
        "tweets_list = [[ tweet.id, tweet.created_at, tweet.text] for tweet in tweets]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "xk8pXtS6cDlx",
        "outputId": "2e825a0a-626c-4b44-ecb5-d4031085691c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1515684197901701122,\n",
              " datetime.datetime(2022, 4, 17, 13, 30, 47, tzinfo=datetime.timezone.utc),\n",
              " 'Four Deep Learning Papers to Read in December 2021 https://t.co/V2mett00qb']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_list[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBH5FZfjcDly"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEwjqraecDly"
      },
      "outputs": [],
      "source": [
        "# Creation of dataframe from tweets list\n",
        "# Add or remove columns as you remove tweet information\n",
        "tweets_df = pd.DataFrame(tweets_list,columns=['Tweet Id', 'Datetime', 'tweet'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3lOq5UycDly",
        "outputId": "c8eb6ab7-8ad6-42b2-858c-c63fd6a0e56f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet Id</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1515684197901701122</td>\n",
              "      <td>2022-04-17 13:30:47+00:00</td>\n",
              "      <td>Four Deep Learning Papers to Read in December ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1515684009208164356</td>\n",
              "      <td>2022-04-17 13:30:02+00:00</td>\n",
              "      <td>Out now ðŸ“¤: \"Deep reinforcement learning-based ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1515683818304425989</td>\n",
              "      <td>2022-04-17 13:29:16+00:00</td>\n",
              "      <td>Deep Learning Prerequisites: Logistic Regressi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1515683752177025026</td>\n",
              "      <td>2022-04-17 13:29:01+00:00</td>\n",
              "      <td>The Principles of Deep Learning Theory https:/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1515683140446330889</td>\n",
              "      <td>2022-04-17 13:26:35+00:00</td>\n",
              "      <td>Legal Document Retrieval using Document Vector...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1515605653443723267</td>\n",
              "      <td>2022-04-17 08:18:41+00:00</td>\n",
              "      <td>Deep Learning In Javascript - https://t.co/jnC...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1515605488620220416</td>\n",
              "      <td>2022-04-17 08:18:01+00:00</td>\n",
              "      <td>Image Data Prep for Deep Learning Model #data ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1515605166661242882</td>\n",
              "      <td>2022-04-17 08:16:44+00:00</td>\n",
              "      <td>onal Market Forecast Report 2022 â€“ 2028 â€“ LeRo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1515605041662603267</td>\n",
              "      <td>2022-04-17 08:16:15+00:00</td>\n",
              "      <td>Interesting article: Neuro-symbolic methods ou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1515604910477398018</td>\n",
              "      <td>2022-04-17 08:15:43+00:00</td>\n",
              "      <td>An Attempt at Demystifying Graph Deep Learning...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Tweet Id                  Datetime  \\\n",
              "0   1515684197901701122 2022-04-17 13:30:47+00:00   \n",
              "1   1515684009208164356 2022-04-17 13:30:02+00:00   \n",
              "2   1515683818304425989 2022-04-17 13:29:16+00:00   \n",
              "3   1515683752177025026 2022-04-17 13:29:01+00:00   \n",
              "4   1515683140446330889 2022-04-17 13:26:35+00:00   \n",
              "..                  ...                       ...   \n",
              "95  1515605653443723267 2022-04-17 08:18:41+00:00   \n",
              "96  1515605488620220416 2022-04-17 08:18:01+00:00   \n",
              "97  1515605166661242882 2022-04-17 08:16:44+00:00   \n",
              "98  1515605041662603267 2022-04-17 08:16:15+00:00   \n",
              "99  1515604910477398018 2022-04-17 08:15:43+00:00   \n",
              "\n",
              "                                                tweet  \n",
              "0   Four Deep Learning Papers to Read in December ...  \n",
              "1   Out now ðŸ“¤: \"Deep reinforcement learning-based ...  \n",
              "2   Deep Learning Prerequisites: Logistic Regressi...  \n",
              "3   The Principles of Deep Learning Theory https:/...  \n",
              "4   Legal Document Retrieval using Document Vector...  \n",
              "..                                                ...  \n",
              "95  Deep Learning In Javascript - https://t.co/jnC...  \n",
              "96  Image Data Prep for Deep Learning Model #data ...  \n",
              "97  onal Market Forecast Report 2022 â€“ 2028 â€“ LeRo...  \n",
              "98  Interesting article: Neuro-symbolic methods ou...  \n",
              "99  An Attempt at Demystifying Graph Deep Learning...  \n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "t0pBimcocDly",
        "outputId": "0ca5df6c-bc87-4997-851a-fbeaaf8aa0d0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet Id</th>\n",
              "      <th>Datetime</th>\n",
              "      <th>tweet</th>\n",
              "      <th>clean_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1515684197901701122</td>\n",
              "      <td>2022-04-17 13:30:47+00:00</td>\n",
              "      <td>Four Deep Learning Papers to Read in December ...</td>\n",
              "      <td>Four Deep Learning Papers to Read in December ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1515684009208164356</td>\n",
              "      <td>2022-04-17 13:30:02+00:00</td>\n",
              "      <td>Out now ðŸ“¤: \"Deep reinforcement learning-based ...</td>\n",
              "      <td>Out now Deep reinforcement learning based mult...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1515683818304425989</td>\n",
              "      <td>2022-04-17 13:29:16+00:00</td>\n",
              "      <td>Deep Learning Prerequisites: Logistic Regressi...</td>\n",
              "      <td>Deep Learning Prerequisites Logistic Regressio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1515683752177025026</td>\n",
              "      <td>2022-04-17 13:29:01+00:00</td>\n",
              "      <td>The Principles of Deep Learning Theory https:/...</td>\n",
              "      <td>The Principles of Deep Learning Theory ai mach...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1515683140446330889</td>\n",
              "      <td>2022-04-17 13:26:35+00:00</td>\n",
              "      <td>Legal Document Retrieval using Document Vector...</td>\n",
              "      <td>Legal Document Retrieval using Document Vector...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>1515605653443723267</td>\n",
              "      <td>2022-04-17 08:18:41+00:00</td>\n",
              "      <td>Deep Learning In Javascript - https://t.co/jnC...</td>\n",
              "      <td>Deep Learning In Javascript bigdata deeplearning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>1515605488620220416</td>\n",
              "      <td>2022-04-17 08:18:01+00:00</td>\n",
              "      <td>Image Data Prep for Deep Learning Model #data ...</td>\n",
              "      <td>Image Data Prep for Deep Learning Model data s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>1515605166661242882</td>\n",
              "      <td>2022-04-17 08:16:44+00:00</td>\n",
              "      <td>onal Market Forecast Report 2022 â€“ 2028 â€“ LeRo...</td>\n",
              "      <td>onal Market Forecast Report 2022 2028 LeRoy Fa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>1515605041662603267</td>\n",
              "      <td>2022-04-17 08:16:15+00:00</td>\n",
              "      <td>Interesting article: Neuro-symbolic methods ou...</td>\n",
              "      <td>Interesting article Neuro symbolic methods out...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>1515604910477398018</td>\n",
              "      <td>2022-04-17 08:15:43+00:00</td>\n",
              "      <td>An Attempt at Demystifying Graph Deep Learning...</td>\n",
              "      <td>An Attempt at Demystifying Graph Deep Learning...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               Tweet Id                  Datetime  \\\n",
              "0   1515684197901701122 2022-04-17 13:30:47+00:00   \n",
              "1   1515684009208164356 2022-04-17 13:30:02+00:00   \n",
              "2   1515683818304425989 2022-04-17 13:29:16+00:00   \n",
              "3   1515683752177025026 2022-04-17 13:29:01+00:00   \n",
              "4   1515683140446330889 2022-04-17 13:26:35+00:00   \n",
              "..                  ...                       ...   \n",
              "95  1515605653443723267 2022-04-17 08:18:41+00:00   \n",
              "96  1515605488620220416 2022-04-17 08:18:01+00:00   \n",
              "97  1515605166661242882 2022-04-17 08:16:44+00:00   \n",
              "98  1515605041662603267 2022-04-17 08:16:15+00:00   \n",
              "99  1515604910477398018 2022-04-17 08:15:43+00:00   \n",
              "\n",
              "                                                tweet  \\\n",
              "0   Four Deep Learning Papers to Read in December ...   \n",
              "1   Out now ðŸ“¤: \"Deep reinforcement learning-based ...   \n",
              "2   Deep Learning Prerequisites: Logistic Regressi...   \n",
              "3   The Principles of Deep Learning Theory https:/...   \n",
              "4   Legal Document Retrieval using Document Vector...   \n",
              "..                                                ...   \n",
              "95  Deep Learning In Javascript - https://t.co/jnC...   \n",
              "96  Image Data Prep for Deep Learning Model #data ...   \n",
              "97  onal Market Forecast Report 2022 â€“ 2028 â€“ LeRo...   \n",
              "98  Interesting article: Neuro-symbolic methods ou...   \n",
              "99  An Attempt at Demystifying Graph Deep Learning...   \n",
              "\n",
              "                                           clean_text  \n",
              "0   Four Deep Learning Papers to Read in December ...  \n",
              "1   Out now Deep reinforcement learning based mult...  \n",
              "2   Deep Learning Prerequisites Logistic Regressio...  \n",
              "3   The Principles of Deep Learning Theory ai mach...  \n",
              "4   Legal Document Retrieval using Document Vector...  \n",
              "..                                                ...  \n",
              "95   Deep Learning In Javascript bigdata deeplearning  \n",
              "96  Image Data Prep for Deep Learning Model data s...  \n",
              "97  onal Market Forecast Report 2022 2028 LeRoy Fa...  \n",
              "98  Interesting article Neuro symbolic methods out...  \n",
              "99  An Attempt at Demystifying Graph Deep Learning...  \n",
              "\n",
              "[100 rows x 4 columns]"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# clean tweet \n",
        "tweets_df[\"clean_text\"] = tweets_df[\"tweet\"].apply(lambda tweet: clean_tweet(tweet))\n",
        "tweets_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bfaq6K2QcDlz"
      },
      "outputs": [],
      "source": [
        "tweets_df[\"score\"] = tweets_df[\"clean_text\"].apply(lambda review:sid.polarity_scores(review))\n",
        "# tweets_df.iloc[0]\n",
        "tweets_df[\"score\"][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qc2cNViYcDlz"
      },
      "outputs": [],
      "source": [
        "tweets_df[\"compound\"] = tweets_df[\"score\"].apply(lambda d:d[\"compound\"])\n",
        "tweets_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zsFP-jB8cDlz"
      },
      "outputs": [],
      "source": [
        "tweets_df[\"sentiment\"] = tweets_df[\"compound\"].apply(lambda  score : get_tweet_sentiment(score))\n",
        "tweets_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctxVxjpFcDlz"
      },
      "outputs": [],
      "source": [
        "del tweets_df[\"score\"]\n",
        "del tweets_df[\"compound\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utMWcJObcDlz"
      },
      "outputs": [],
      "source": [
        "tweets = []\n",
        "\n",
        "def text_query_to_csv(text_query,count):\n",
        "    try:\n",
        "        \n",
        "        query = text_query + \" \" + \"-filter:retweets\"\n",
        "        # Creation of query method using parameters\n",
        "        tweets = tweepy.Cursor(api.search,q=query).items(count)\n",
        "\n",
        "        # Pulling information from tweets iterable object\n",
        "        tweets_list = [[ tweet.id, tweet.created_at, tweet.text] for tweet in tweets]\n",
        "        \n",
        "    \n",
        "        # Creation of dataframe from tweets list\n",
        "        # Add or remove columns as you remove tweet information\n",
        "        tweets_df = pd.DataFrame(tweets_list,columns=['Tweet Id', 'Datetime', 'tweet'])\n",
        "        \n",
        "        # clean tweet \n",
        "        tweets_df[\"clean_text\"] = tweets_df[\"tweet\"].apply(lambda tweet: clean_tweet(tweet))\n",
        "        \n",
        "        tweets_df[\"score\"] = tweets_df[\"clean_text\"].apply(lambda review:sid.polarity_scores(review))\n",
        "        \n",
        "        tweets_df[\"compound\"] = tweets_df[\"score\"].apply(lambda d:d[\"compound\"])\n",
        "        tweets_df[\"sentiment\"] = tweets_df[\"compound\"].apply(lambda  score : get_tweet_sentiment(score))\n",
        "        \n",
        "        del tweets_df[\"score\"]\n",
        "        del tweets_df[\"compound\"]\n",
        "        \n",
        "      \n",
        "        return tweets_df\n",
        "\n",
        "    except BaseException as e:\n",
        "        print('failed on_status,',str(e))\n",
        "        time.sleep(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq3v8MlBcDl0"
      },
      "source": [
        "# Amazon India"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8lhm2h0cDl0"
      },
      "outputs": [],
      "source": [
        "amazon_india = text_query_to_csv(\"amazon india\",150) # 3000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QP3v37MTcDl0"
      },
      "outputs": [],
      "source": [
        "amazon_india.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOh4GPfQcDl0"
      },
      "outputs": [],
      "source": [
        "amazon_india.to_csv('{}-tweets.csv'.format(\"amazon_india\"), sep=',', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nafcu6a-cDl1"
      },
      "outputs": [],
      "source": [
        "amazon_india.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I0-m2k9cDl1"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TPXksPccDl1"
      },
      "source": [
        "# Flipkart"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9kHEnV4cDl1"
      },
      "outputs": [],
      "source": [
        "flipkart = text_query_to_csv(\"flipkart\", 150) # 15mins time to compelte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIPWxVBucDl1"
      },
      "outputs": [],
      "source": [
        "flipkart.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQmPxesrcDl1"
      },
      "outputs": [],
      "source": [
        "flipkart.to_csv('{}-tweets.csv'.format(\"flipkart\"), sep=',', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qLvOOPKdcDl1"
      },
      "outputs": [],
      "source": [
        "flipkart.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZmWgORJcDl2"
      },
      "source": [
        "# snapdeal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHluy2tVcDl2"
      },
      "outputs": [],
      "source": [
        "snapdeal = text_query_to_csv(\"snapdeal\", 150) # 15mins time to compelte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVy7tiv_cDl2"
      },
      "outputs": [],
      "source": [
        "snapdeal.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpdmK7TEcDl2"
      },
      "outputs": [],
      "source": [
        "snapdeal.to_csv('{}-tweets.csv'.format(\"snapdeal\"), sep=',', index = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Be33hT32cDl2"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wB2yd5NncDl2"
      },
      "outputs": [],
      "source": [
        "ax = sns.countplot(x=\"sentiment\", data=amazon_india)\n",
        "plt.ylim(0, amazon_india.shape[0])\n",
        "plt.title(\"Amazon India\")\n",
        "print()\n",
        "\n",
        "pos = round(amazon_india[\"sentiment\"].value_counts()[0]/len(amazon_india) * 100, 2)\n",
        "neu = round(amazon_india[\"sentiment\"].value_counts()[1]/len(amazon_india) * 100, 2)\n",
        "neg = round(amazon_india[\"sentiment\"].value_counts()[2]/len(amazon_india) * 100, 2)\n",
        "print(\"For Amazon India...\")\n",
        "print('Positive tweets percentage: {} %'.format(pos))\n",
        "print('Negative tweets percentage: {} %'.format(neg))\n",
        "print('Neutral tweets percentage: {} %'.format(neu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DUxyfgWvcDl2"
      },
      "outputs": [],
      "source": [
        "ax = sns.countplot(x=\"sentiment\", data=flipkart)\n",
        "plt.ylim(0, flipkart.shape[0])\n",
        "plt.title(\"flipkart\")\n",
        "print()\n",
        "\n",
        "pos = round(flipkart[\"sentiment\"].value_counts()[0]/len(flipkart) * 100, 2)\n",
        "neu = round(flipkart[\"sentiment\"].value_counts()[1]/len(flipkart) * 100, 2)\n",
        "neg = round(flipkart[\"sentiment\"].value_counts()[2]/len(flipkart) * 100, 2)\n",
        "print(\"For flipkart ...\")\n",
        "print('Positive tweets percentage: {} %'.format(pos))\n",
        "print('Negative tweets percentage: {} %'.format(neg))\n",
        "print('Neutral tweets percentage: {} %'.format(neu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aQAiwXNcDl3"
      },
      "outputs": [],
      "source": [
        "ax = sns.countplot(x=\"sentiment\", data=snapdeal)\n",
        "plt.ylim(0, snapdeal.shape[0])\n",
        "plt.title(\"snapdeal\")\n",
        "print()\n",
        "\n",
        "pos = round(snapdeal[\"sentiment\"].value_counts()[0]/len(snapdeal) * 100, 2)\n",
        "neu = round(snapdeal[\"sentiment\"].value_counts()[1]/len(snapdeal) * 100, 2)\n",
        "neg = round(snapdeal[\"sentiment\"].value_counts()[2]/len(snapdeal) * 100, 2)\n",
        "print(\"For snapdeal ...\")\n",
        "print('Positive tweets percentage: {} %'.format(pos))\n",
        "print('Negative tweets percentage: {} %'.format(neg))\n",
        "print('Neutral tweets percentage: {} %'.format(neu))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw2E7WkscDl3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C44WId0ScDl3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_MDpV8QcDl3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "twitter sentiment analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "aq3v8MlBcDl0",
        "9TPXksPccDl1",
        "WZmWgORJcDl2"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}